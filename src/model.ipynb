{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_path = \"/home/hpc01/Marcos/Patch_Assesment/Tokenizer\"\n",
    "tokenized_dataset_path = \"/home/hpc01/Marcos/Patch_Assesment/Dataset/TokenizedDatasets/small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "tokenized_datasets = load_from_disk(tokenized_dataset_path)\n",
    "\n",
    "pad_token_id = tokenizer.convert_tokens_to_ids(\"<|end_of_text|>\")  # Obtener el id de <|pad|>\n",
    "batch_size = 4\n",
    "\n",
    "def create_batches(dataset, batch_size, pad_token_id = 128001):\n",
    "    \"\"\"\n",
    "    Iterador que divide el dataset en batches y añade padding para igualar las secuencias al tamaño máximo del batch.\n",
    "\n",
    "    Args:\n",
    "    - dataset: dataset tokenizado (e.g., tokenized_datasets[\"train\"]).\n",
    "    - batch_size: tamaño del batch.\n",
    "    - pad_token_id: id del token de padding (en este caso, el id de <|pad|>).\n",
    "\n",
    "    Yields:\n",
    "    - batch: un batch que contiene 'input_ids', 'attention_mask' y 'labels'.\n",
    "    \"\"\"\n",
    "    # Iterar sobre el dataset en pasos del tamaño del batch\n",
    "    for i in range(0, len(dataset['input_ids']), batch_size):\n",
    "        # Extraer el batch actual\n",
    "        batch_input_ids = dataset['input_ids'][i:i + batch_size]\n",
    "        batch_attention_mask = dataset['attention_mask'][i:i + batch_size]\n",
    "        batch_labels = dataset['labels'][i:i + batch_size]\n",
    "\n",
    "        # Encontrar la longitud máxima de 'input_ids' en el batch actual\n",
    "        max_length = max(len(input_ids) for input_ids in batch_input_ids)+1\n",
    "\n",
    "        # Crear listas para almacenar los input_ids y attention_mask con padding\n",
    "        padded_input_ids = []\n",
    "        padded_attention_mask = []\n",
    "\n",
    "        # Aplicar padding a cada secuencia del batch\n",
    "        for input_ids, attention_mask in zip(batch_input_ids, batch_attention_mask):\n",
    "            # Calcular cuántos tokens de padding se necesitan\n",
    "            padding_length = max_length - len(input_ids)\n",
    "            \n",
    "            # Rellenar con el token de padding\n",
    "            padded_input_ids.append(input_ids + [pad_token_id] * padding_length)\n",
    "            padded_attention_mask.append(attention_mask + [0] * padding_length)  # 0 para los tokens de padding\n",
    "        \n",
    "        # Yield del batch actual\n",
    "        yield {\n",
    "            'input_ids': torch.tensor(padded_input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(padded_attention_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(batch_labels, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "pad_token_id = tokenizer.convert_tokens_to_ids(\"<|end_of_text|>\")  # Obtener el id de <|pad|>\n",
    "batch_size = 4\n",
    "\n",
    "batch_gen_train = create_batches(tokenized_datasets[\"train\"], batch_size, pad_token_id)\n",
    "\n",
    "batch = next(batch_gen_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel, LlamaConfig, AutoModel, AutoConfig\n",
    "from torch import nn\n",
    "\n",
    "class PatchALlama(PreTrainedModel):\n",
    "    \"\"\"\n",
    "    Creates a DeBERTa model for fault localization.\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = LlamaConfig\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PatchALlama, self).__init__(AutoConfig.from_pretrained(\"meta-llama/Llama-3.2-1B\"))\n",
    "\n",
    "        self.llama = AutoModel.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "        self.linear = nn.Linear(self.llama.config.hidden_size, 1)\n",
    "\n",
    "    def first_eots_pos(self, input_ids):\n",
    "        r_tensor = []\n",
    "\n",
    "        for input in input_ids:\n",
    "\n",
    "            condicion = (input == 128001)\n",
    "            r_tensor.append(torch.nonzero(condicion)[0].item())\n",
    "\n",
    "        return r_tensor\n",
    "\n",
    "    def get_last_tokens(self, last_hidden_state, input_ids):\n",
    "        ids = self.first_eots_pos(input_ids)\n",
    "\n",
    "        tokens = []\n",
    "\n",
    "        for i in range(len(input_ids)):\n",
    "            tokens.append(last_hidden_state[i][ids[i]])\n",
    "\n",
    "        return torch.stack(tokens)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask,labels):\n",
    "\n",
    "        output = self.llama(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = output[\"last_hidden_state\"]\n",
    "        #Del last hidden state tengo que buscar el último eos que es el que tiene todo el contexto del fragmento del batch\n",
    "        last_token = self.get_last_tokens(last_hidden_state, input_ids)\n",
    "\n",
    "        output_lin = self.linear(last_token).squeeze(-1)\n",
    "        # Output: [batch_size, number_of_lines, 1] -> [batch_size, number_of_lines]\n",
    "\n",
    "        # Flatten output tensor\n",
    "        output = output_lin.view(-1)\n",
    "\n",
    "        # Labels \n",
    "        loss_fnc = nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fnc(output, labels.float())\n",
    "\n",
    "        return (loss, output) if loss is not None else output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "model = PatchALlama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = batch[\"input_ids\"]\n",
    "attention_mask = batch[\"attention_mask\"]\n",
    "labels = batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7106, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n",
       " tensor([1.1449, 0.0908, 0.5000, 0.4496], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids, attention_mask, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(labels.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>@@ -140,7 +140,6 @@\n",
      "        */\n",
      "       if (NodeUtil.hasFinally(n)) {\n",
      "         Node finallyBlock = n.getLastChild();\n",
      "-        tryMinimizeExits(finallyBlock, exitType, labelName);\n",
      "       }\n",
      "     }\n",
      "\n",
      "<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53, 183, 69, 118]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def first_eots_pos(input_ids):\n",
    "    r_tensor = []\n",
    "\n",
    "    for i, input in enumerate(input_ids):\n",
    "\n",
    "        condicion = (input == 128001)\n",
    "        r_tensor.append(torch.nonzero(condicion)[0].item())\n",
    "\n",
    "    return r_tensor\n",
    "\n",
    "first_eots = first_eots_pos(input_ids)\n",
    "first_eots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5497, -1.5041,  2.7454,  ..., -0.6332,  0.6005, -1.0105],\n",
       "         [-3.0679,  3.7994,  1.1108,  ..., -8.1647, -2.2493, -1.1095],\n",
       "         [ 0.5897,  2.4325,  0.9655,  ..., -4.2744,  0.1402, -0.4675],\n",
       "         ...,\n",
       "         [-0.1433,  3.2924, -0.7329,  ...,  0.5978,  2.6403,  1.5293],\n",
       "         [-0.1700,  3.2424, -0.7118,  ...,  0.6912,  2.5687,  1.5834],\n",
       "         [-0.1510,  3.2228, -0.6738,  ...,  0.7782,  2.4936,  1.5973]],\n",
       "\n",
       "        [[ 1.5497, -1.5041,  2.7454,  ..., -0.6332,  0.6005, -1.0105],\n",
       "         [-3.0679,  3.7994,  1.1108,  ..., -8.1647, -2.2492, -1.1095],\n",
       "         [ 0.5897,  2.4325,  0.9655,  ..., -4.2744,  0.1402, -0.4675],\n",
       "         ...,\n",
       "         [ 0.8978, -1.5651,  1.3260,  ..., -0.8632, -3.4923, -1.1031],\n",
       "         [-2.2748, -1.1865,  1.3182,  ..., -0.7239, -0.1708,  0.0831],\n",
       "         [ 1.3420,  3.1930, -2.2678,  ..., -0.9257,  4.1256,  1.7292]],\n",
       "\n",
       "        [[ 1.5497, -1.5041,  2.7454,  ..., -0.6332,  0.6005, -1.0105],\n",
       "         [-3.0679,  3.7994,  1.1108,  ..., -8.1647, -2.2492, -1.1095],\n",
       "         [ 0.5897,  2.4325,  0.9655,  ..., -4.2744,  0.1402, -0.4675],\n",
       "         ...,\n",
       "         [ 0.3076,  3.1115, -0.6900,  ...,  0.6028,  2.3942,  1.1587],\n",
       "         [ 0.3533,  3.1084, -0.6843,  ...,  0.7211,  2.3056,  1.2211],\n",
       "         [ 0.3968,  3.1351, -0.6721,  ...,  0.7938,  2.2310,  1.2603]],\n",
       "\n",
       "        [[ 1.5497, -1.5041,  2.7454,  ..., -0.6332,  0.6005, -1.0105],\n",
       "         [-3.0679,  3.7994,  1.1108,  ..., -8.1647, -2.2493, -1.1095],\n",
       "         [ 0.5897,  2.4325,  0.9655,  ..., -4.2744,  0.1402, -0.4675],\n",
       "         ...,\n",
       "         [ 0.1602,  3.1437, -1.3859,  ...,  0.3379,  2.6136,  0.2502],\n",
       "         [ 0.2273,  3.0414, -1.3991,  ...,  0.3711,  2.5082,  0.4063],\n",
       "         [ 0.3178,  3.0026, -1.4518,  ...,  0.4195,  2.4772,  0.5216]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.llama(input_ids=input_ids, attention_mask=attention_mask)\n",
    "last_hidden_state = output[\"last_hidden_state\"]\n",
    "        #Del last hidden state tengo que buscar el último eos que es el que tiene todo el contexto del fragmento del batch\n",
    "last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53, 183, 69, 118]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5489,  4.9625, -3.5646,  ..., -1.9848,  4.0793,  1.2826],\n",
       "        [ 1.3420,  3.1930, -2.2678,  ..., -0.9257,  4.1256,  1.7292],\n",
       "        [ 2.0299,  4.0167, -3.0058,  ..., -0.8630,  4.5257,  1.7899],\n",
       "        [ 2.6225,  4.2697, -3.1690,  ..., -0.3946,  4.6472,  1.9237]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_last_tokens(last_hidden_state, input_ids):\n",
    "    ids = first_eots_pos(input_ids)\n",
    "    print(ids)\n",
    "    tokens = []\n",
    "\n",
    "    for i in range(len(input_ids)):\n",
    "        tokens.append(last_hidden_state[i][ids[i]])\n",
    "\n",
    "    return torch.stack(tokens)\n",
    "\n",
    "last_tokens = get_last_tokens(last_hidden_state, input_ids)\n",
    "last_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8786, -0.3365, -0.6402, -0.8607], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output_lin = model.linear(last_tokens).squeeze(-1)\n",
    "        # Output: [batch_size, number_of_lines, 1] -> [batch_size, number_of_lines]\n",
    "output_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8786, -0.3365, -0.6402, -0.8607], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "        # Flatten output tensor\n",
    "output = output_lin.view(-1)\n",
    "\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7194, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "        # Labels \n",
    "loss_fnc = nn.BCEWithLogitsLoss()\n",
    "loss = loss_fnc(output, labels.float())\n",
    "\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marcos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
